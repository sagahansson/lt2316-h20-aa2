{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aa1 stuff\n",
    "from aa1 import DataLoader\n",
    "from aa1 import extract_features\n",
    "from aa1 import check_output\n",
    "\n",
    "from aa2 import Trainer\n",
    "from aa2 import parallel_coordinates\n",
    "# <-- IMPORT YOUR MODEL CLASS HERE\n",
    "from aa2.model import Net\n",
    "\n",
    "# saga\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda:3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tic = time.perf_counter()\n",
    "#\n",
    "## assigment 1 stuff\n",
    "#\n",
    "#dataset = DataLoader(data_dir=\"../DDICorpus/\", device=device)\n",
    "#train_y, val_y, test_y = check_output(dataset.get_y())\n",
    "#train_X, val_X, test_X = check_output(extract_features(\n",
    "#                                                        data=dataset.data_df,\n",
    "#                                                        max_sample_length=dataset.max_sample_length,\n",
    "#                                                        id2word=dataset.id2word\n",
    "#                                                       ))\n",
    "#toc = time.perf_counter()\n",
    "#print(f\"Downloaded the tutorial in {toc - tic:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_tensors = {'train_y': train_y, 'val_y': val_y, 'test_y': test_y, 'train_X': train_X, 'val_X' : val_X, 'test_X' : test_X }\n",
    "#torch.save(my_tensors, 'my_tensors.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_tensors = torch.load('my_tensors.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = loaded_tensors['train_y']\n",
    "val_y = loaded_tensors['val_y']\n",
    "test_y = loaded_tensors['test_y']\n",
    "train_X = loaded_tensors['train_X']\n",
    "val_X = loaded_tensors['val_X']\n",
    "test_X = loaded_tensors['test_X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up trainer\n",
    "model_dump = \"./aa2_models/\" #you are allowed to change the dump_folder\n",
    "trainer = Trainer(dump_folder=model_dump, device=device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a set of hyperparamaters\n",
    "# test at least 5 different sets of hyperparamaters \n",
    "set_hyperparamaters = [\n",
    "                        # Example:\n",
    "                        {\n",
    "                            \"learning_rate\": 0.01,\n",
    "                            \"number_layers\": 5,\n",
    "                            \"epochs\" : 40,\n",
    "                            \"hid_dim\" : 10,\n",
    "                            \"optimizer\" : \"Adam\",\n",
    "                            \"loss_funct\" : \"L1Loss\", #L1Loss MSELoss CrossEntropyLoss\n",
    "                            \"model_name\" : \"model1\"\n",
    "                        }\n",
    "                        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1Loss\n",
      "Total loss in epoch 0 is 2.7317469120025635\n",
      "Total loss in epoch 1 is 1.587512731552124\n",
      "Total loss in epoch 2 is 1.589403748512268\n",
      "Total loss in epoch 3 is 1.5823496580123901\n",
      "Total loss in epoch 4 is 1.575413465499878\n",
      "Total loss in epoch 5 is 1.57441246509552\n",
      "Total loss in epoch 6 is 1.5574455261230469\n",
      "Total loss in epoch 7 is 1.5511753559112549\n",
      "Total loss in epoch 8 is 1.5510259866714478\n",
      "Total loss in epoch 9 is 1.5453699827194214\n",
      "Total loss in epoch 10 is 1.5504968166351318\n",
      "Total loss in epoch 11 is 1.5443956851959229\n",
      "Total loss in epoch 12 is 1.5383622646331787\n",
      "Total loss in epoch 13 is 1.520812749862671\n",
      "Total loss in epoch 14 is 1.524733304977417\n",
      "Total loss in epoch 15 is 1.5186820030212402\n",
      "Total loss in epoch 16 is 1.5166480541229248\n",
      "Total loss in epoch 17 is 1.526395320892334\n",
      "Total loss in epoch 18 is 1.5156854391098022\n",
      "Total loss in epoch 19 is 1.5117372274398804\n",
      "Total loss in epoch 20 is 1.513905644416809\n",
      "Total loss in epoch 21 is 1.5171654224395752\n",
      "Total loss in epoch 22 is 1.509480595588684\n",
      "Total loss in epoch 23 is 1.5104222297668457\n",
      "Total loss in epoch 24 is 1.5097068548202515\n",
      "Total loss in epoch 25 is 1.5044310092926025\n",
      "Total loss in epoch 26 is 1.5039089918136597\n",
      "Total loss in epoch 27 is 1.5157803297042847\n",
      "Total loss in epoch 28 is 1.5105855464935303\n",
      "Total loss in epoch 29 is 1.5084718465805054\n",
      "Total loss in epoch 30 is 1.5055701732635498\n",
      "Total loss in epoch 31 is 1.5044878721237183\n",
      "Total loss in epoch 32 is 1.5082789659500122\n",
      "Total loss in epoch 33 is 1.5094650983810425\n",
      "Total loss in epoch 34 is 1.5037078857421875\n",
      "Total loss in epoch 35 is 1.5133941173553467\n",
      "Total loss in epoch 36 is 1.507993221282959\n",
      "Total loss in epoch 37 is 1.5042794942855835\n",
      "Total loss in epoch 38 is 1.50653874874115\n",
      "Total loss in epoch 39 is 1.5038362741470337\n",
      "Model name: model1, \n",
      " Accuracy: 0.9939056703762587, \n",
      " Precision: 0.9878484816060801, Recall: 0.9939056703762587, F1-Score:0.9908678191578328\n",
      "hello got all the way here\n",
      "Time elapsed: 183.9551 seconds\n",
      "18:51:38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gushansad@GU.GU.SE/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# hyperparamater tuning\n",
    "# train you model with your set of hyperparamaters\n",
    "tic = time.perf_counter()\n",
    "for hp in set_hyperparamaters:\n",
    "    hello = trainer.train(train_X, train_y, val_X, val_y, Net, hp)\n",
    "toc = time.perf_counter()\n",
    "print(f\"Time elapsed: {toc - tic:0.4f} seconds\")\n",
    "t = time.localtime()\n",
    "current_time = time.strftime(\"%H:%M:%S\", t)\n",
    "print(current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(profile=\"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(hello.shape[0]):\n",
    "    predict_sent = hello[i]\n",
    "    for j in range(len(predict_sent)):\n",
    "        predict_tok = torch.round(predict_sent[j])\n",
    "        if predict_tok != 0:\n",
    "            print(predict_tok)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "for split in bl:\n",
    "    for X, y in split:\n",
    "        predictions = m(X.float(), self.device)\n",
    "        labels = y\n",
    "        for i in range(predictions.shape[0]):\n",
    "            predict_sent = predictions[i].tolist()\n",
    "            label_sent = labels[i].tolist()\n",
    "            for j in range(len(predict_sent)):\n",
    "                predict_tok = round(predict_sent[j])\n",
    "                label_tok = label_sent[j]\n",
    "                y_true.append(label_tok)\n",
    "                y_pred.append(predict_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(hello.shape[0]):\n",
    "    predict_sent = hello[i].tolist()\n",
    "    for j in range(len(predict_sent)):\n",
    "        predict_tok = round(predict_sent[j])\n",
    "        print(predict_tok)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for i, x in enumerate(hello):\n",
    "    if i==1:\n",
    "        spoijfspd\n",
    "    for ix, y in enumerate(x):\n",
    "        print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hi in hello:\n",
    "    for x, y in hi:\n",
    "        for i, sent in enumerate(x):\n",
    "            labels = y[i]\n",
    "            print(sent, labels)\n",
    "            \n",
    "            \n",
    "        \n",
    "            asn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a parallel coordination plot over hyperparamaters\n",
    "# add path to models and change metric to what ever metric you have chosen to use/want to use\n",
    "parallel_coordinates(model_dump, metric=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the Parallel Coordination plot define 3 new hyperparamaters set thay you \n",
    "# think are worth testing\n",
    "set_hyperparamaters_2 = [\n",
    "                        # Example:\n",
    "                        # {\n",
    "                        #   \"learning_rate\": 0.1,\n",
    "                        #   \"number_layers\": 3,\n",
    "                        #   \"optimizer\": \"adam\",\n",
    "                            \n",
    "                        # }\n",
    "                        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train models for the new hyperparamaters\n",
    "for hp in set_hyperparamaters_2:\n",
    "    trainer.train(train_X, train_y, val_X, val_y, YOUR_MODEL_CLASS, hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a parallel coordination plot over hyperparamaters again\n",
    "parallel_coordinates(model_dump, metric=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose the best model base on the last parallel coordination plot\n",
    "best_model_path = \"PATH TO THE BEST MODEL\"\n",
    "scores = trainer.test(test_X, test_y, YOUR_MODEL_CLASS, best_model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
